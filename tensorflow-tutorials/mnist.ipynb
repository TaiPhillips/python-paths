{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "  \"\"\"Model function for CNN.\"\"\"\n",
    "  # Input Layer\n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2 and Pooling Layer #2\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Dense Layer\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits Layer\n",
    "  logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])\n",
    "  }\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and eval data\n",
    "((train_data, train_labels),\n",
    " (eval_data, eval_labels)) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_data = train_data/np.float32(255)\n",
    "train_labels = train_labels.astype(np.int32)  # not required\n",
    "\n",
    "eval_data = eval_data/np.float32(255)\n",
    "eval_labels = eval_labels.astype(np.int32)  # not required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0821 04:35:32.217553 140686840100672 estimator.py:1790] Using default config.\n",
      "I0821 04:35:32.220106 140686840100672 estimator.py:209] Using config: {'_model_dir': '/tmp/mnist_convnet_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff3872a2fd0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Create the Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging for predictions\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, every_n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},\n",
    "    y=train_labels,\n",
    "    batch_size=100,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0821 04:35:33.127382 140686840100672 deprecation.py:323] From /home/dreuter/.julia/conda/3/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0821 04:35:33.143716 140686840100672 deprecation.py:323] From /home/dreuter/.julia/conda/3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0821 04:35:33.149583 140686840100672 deprecation.py:323] From /home/dreuter/.julia/conda/3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "I0821 04:35:33.169344 140686840100672 estimator.py:1145] Calling model_fn.\n",
      "W0821 04:35:33.173038 140686840100672 deprecation.py:323] From <ipython-input-2-16a10fb7f348>:12: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "W0821 04:35:33.176426 140686840100672 deprecation.py:506] From /home/dreuter/.julia/conda/3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0821 04:35:33.534802 140686840100672 deprecation.py:323] From <ipython-input-2-16a10fb7f348>:15: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "W0821 04:35:33.702042 140686840100672 deprecation.py:323] From <ipython-input-2-16a10fb7f348>:28: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0821 04:35:34.028309 140686840100672 deprecation.py:323] From <ipython-input-2-16a10fb7f348>:30: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "W0821 04:35:34.136301 140686840100672 deprecation.py:323] From /home/dreuter/.julia/conda/3/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "I0821 04:35:34.251030 140686840100672 estimator.py:1147] Done calling model_fn.\n",
      "I0821 04:35:34.253165 140686840100672 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0821 04:35:34.372863 140686840100672 monitored_session.py:240] Graph was finalized.\n",
      "W0821 04:35:35.105489 140686840100672 deprecation.py:323] From /home/dreuter/.julia/conda/3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "I0821 04:35:35.106938 140686840100672 saver.py:1280] Restoring parameters from /tmp/mnist_convnet_model/model.ckpt-5007\n",
      "W0821 04:35:35.234512 140686840100672 deprecation.py:323] From /home/dreuter/.julia/conda/3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "I0821 04:35:35.268614 140686840100672 session_manager.py:500] Running local_init_op.\n",
      "I0821 04:35:35.275593 140686840100672 session_manager.py:502] Done running local_init_op.\n",
      "W0821 04:35:35.313470 140686840100672 deprecation.py:323] From /home/dreuter/.julia/conda/3/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "I0821 04:35:35.576363 140686840100672 basic_session_run_hooks.py:606] Saving checkpoints for 5007 into /tmp/mnist_convnet_model/model.ckpt.\n",
      "I0821 04:35:37.251060 140686840100672 basic_session_run_hooks.py:262] probabilities = [[0.00036699 0.00066391 0.00096875 0.9170274  0.00004253 0.00063701\n",
      "  0.00000235 0.00153226 0.07076894 0.00798988]\n",
      " [0.99981636 0.         0.00002308 0.00002152 0.00000006 0.0001177\n",
      "  0.00000316 0.00000042 0.00001327 0.00000445]\n",
      " [0.995968   0.00000001 0.00019139 0.00061143 0.00000005 0.00252081\n",
      "  0.00001527 0.00066103 0.00002018 0.00001183]\n",
      " [0.00080518 0.00851044 0.00565474 0.00322202 0.10224031 0.01253129\n",
      "  0.0019612  0.02765464 0.02484195 0.8125782 ]\n",
      " [0.00017012 0.00000405 0.00004093 0.00379765 0.0000339  0.9904351\n",
      "  0.00002097 0.00003085 0.00540993 0.00005654]\n",
      " [0.0011849  0.02394558 0.00871519 0.00029391 0.00248039 0.05593037\n",
      "  0.8816942  0.00000515 0.02511356 0.00063683]\n",
      " [0.00240567 0.00012011 0.00127804 0.9631053  0.00001231 0.03098632\n",
      "  0.00026649 0.00003812 0.00170571 0.00008189]\n",
      " [0.9682682  0.00001914 0.00106546 0.00908188 0.0001597  0.00854329\n",
      "  0.00992232 0.00013391 0.00156304 0.00124302]\n",
      " [0.00003703 0.00494032 0.00009927 0.00535764 0.06940901 0.01522879\n",
      "  0.00005105 0.02243765 0.02007494 0.86236435]\n",
      " [0.02785777 0.00000002 0.01200502 0.00000841 0.00002884 0.08446536\n",
      "  0.8422453  0.00000002 0.03338088 0.0000084 ]\n",
      " [0.0002712  0.00003164 0.01875245 0.9732132  0.00012085 0.00109998\n",
      "  0.00004015 0.00004558 0.00418964 0.00223535]\n",
      " [0.00043347 0.00183405 0.00010226 0.007163   0.0000707  0.9820294\n",
      "  0.00042363 0.00018625 0.00748305 0.00027418]\n",
      " [0.00000155 0.9956169  0.00023229 0.00155904 0.00013822 0.00001337\n",
      "  0.00026288 0.00023191 0.00151978 0.00042405]\n",
      " [0.00009463 0.00001186 0.00041914 0.00273401 0.00001839 0.00103494\n",
      "  0.00001368 0.00010184 0.9952047  0.00036681]\n",
      " [0.9214979  0.00000921 0.00234732 0.00507802 0.00006497 0.03965792\n",
      "  0.00272285 0.00160078 0.01621549 0.01080543]\n",
      " [0.07745097 0.00021758 0.00015309 0.08433831 0.5237925  0.0645154\n",
      "  0.00354525 0.07287647 0.00552205 0.16758841]\n",
      " [0.00145973 0.00000109 0.00000186 0.00007526 0.00001141 0.99699533\n",
      "  0.00000561 0.0000036  0.0013707  0.00007549]\n",
      " [0.00007162 0.00192793 0.00022015 0.00230049 0.00491636 0.0026177\n",
      "  0.00005907 0.06345654 0.02499278 0.89943737]\n",
      " [0.00001122 0.01022961 0.00007571 0.0168451  0.00047688 0.00714516\n",
      "  0.00000387 0.76468116 0.00889191 0.1916395 ]\n",
      " [0.00527745 0.5076303  0.31659496 0.02617306 0.01860826 0.00696454\n",
      "  0.09715396 0.00271763 0.01523617 0.00364369]\n",
      " [0.00000029 0.00000472 0.00000301 0.00000679 0.9906068  0.00003151\n",
      "  0.0001433  0.00010851 0.00026723 0.00882795]\n",
      " [0.00010761 0.00011357 0.00003787 0.00027619 0.03356989 0.00148826\n",
      "  0.00002779 0.00460197 0.00362675 0.9561501 ]\n",
      " [0.10717054 0.00074199 0.03325898 0.6425204  0.00001118 0.17471263\n",
      "  0.03861997 0.00015064 0.00247403 0.00033961]\n",
      " [0.00001045 0.02859288 0.01622458 0.01428453 0.00416701 0.00046461\n",
      "  0.00006825 0.700799   0.02253312 0.21285552]\n",
      " [0.00580511 0.86051375 0.00795095 0.0084936  0.00371846 0.02895043\n",
      "  0.04405575 0.00176342 0.03033975 0.00840878]\n",
      " [0.00222243 0.00017871 0.94048584 0.04640805 0.00129856 0.00074439\n",
      "  0.0070368  0.00000696 0.00131608 0.00030215]\n",
      " [0.00003386 0.0000125  0.99550015 0.00016179 0.00035531 0.00002916\n",
      "  0.0035903  0.00000018 0.0002665  0.00005025]\n",
      " [0.9978376  0.00000001 0.00071001 0.00003159 0.00000003 0.00118955\n",
      "  0.00017248 0.00000132 0.00005505 0.00000226]\n",
      " [0.00037831 0.94835055 0.02038939 0.00564141 0.001382   0.00167573\n",
      "  0.00989155 0.00243083 0.00751351 0.00234681]\n",
      " [0.00000123 0.00002183 0.0024493  0.00000392 0.00097271 0.00060246\n",
      "  0.9955824  0.00000041 0.00035217 0.00001361]\n",
      " [0.00000496 0.00000108 0.99930274 0.00015423 0.00013481 0.00000012\n",
      "  0.00039435 0.00000021 0.00000059 0.00000674]\n",
      " [0.00011168 0.00000175 0.00000637 0.00012338 0.05527338 0.00012255\n",
      "  0.00000765 0.00555391 0.00029519 0.9385042 ]\n",
      " [0.00015506 0.00144728 0.00015512 0.00047434 0.05208805 0.03197443\n",
      "  0.00184624 0.00060719 0.0316762  0.8795761 ]\n",
      " [0.00003401 0.01009726 0.00022423 0.01476141 0.00110867 0.00061135\n",
      "  0.00001351 0.93814266 0.00095446 0.03405251]\n",
      " [0.00002275 0.00000424 0.0016178  0.00000809 0.00113343 0.00014438\n",
      "  0.99704295 0.00000054 0.00001808 0.00000769]\n",
      " [0.00002565 0.00000585 0.01949563 0.976684   0.00000009 0.00099131\n",
      "  0.00000122 0.00000017 0.00279608 0.00000014]\n",
      " [0.00000903 0.00054453 0.00015969 0.00022253 0.9260046  0.00089882\n",
      "  0.0002366  0.00180353 0.00869214 0.06142863]\n",
      " [0.00009539 0.00009269 0.00000058 0.00059187 0.08468492 0.0013911\n",
      "  0.00003543 0.00170387 0.00085521 0.910549  ]\n",
      " [0.00003408 0.00001011 0.00062173 0.00035533 0.00213392 0.00003964\n",
      "  0.00006506 0.97641945 0.00392794 0.01639272]\n",
      " [0.00046164 0.00229781 0.00108649 0.85641    0.00009948 0.10272878\n",
      "  0.00023139 0.00014132 0.03405812 0.00248497]\n",
      " [0.9985128  0.00000078 0.00035653 0.00043041 0.00000138 0.00036295\n",
      "  0.00002544 0.00004355 0.00006823 0.00019797]\n",
      " [0.00617987 0.00001953 0.16460636 0.00357926 0.01003233 0.00132273\n",
      "  0.0006252  0.6515932  0.00657504 0.15546645]\n",
      " [0.000011   0.9467581  0.00171339 0.00047136 0.00635646 0.00104842\n",
      "  0.0289396  0.00012595 0.01431209 0.00026363]\n",
      " [0.00004681 0.00000338 0.00008215 0.00009622 0.000008   0.00589007\n",
      "  0.0000024  0.00000378 0.9938167  0.00005052]\n",
      " [0.89150363 0.00002942 0.0300541  0.00345905 0.00021954 0.04613028\n",
      "  0.02259571 0.00130494 0.0009478  0.0037555 ]\n",
      " [0.00022583 0.0002824  0.00003645 0.00127668 0.00039567 0.00494459\n",
      "  0.00000397 0.868852   0.00132483 0.12265765]\n",
      " [0.00002185 0.0004806  0.9845301  0.00176986 0.00008803 0.00167164\n",
      "  0.0102348  0.00012891 0.00096406 0.00011015]\n",
      " [0.00002107 0.00021854 0.00001162 0.00009934 0.8855774  0.00017816\n",
      "  0.00029133 0.00056193 0.00058221 0.11245841]\n",
      " [0.00024213 0.9704513  0.00533256 0.00382831 0.0011847  0.00107854\n",
      "  0.00475815 0.00317623 0.00667639 0.00327161]\n",
      " [0.17137036 0.00000025 0.01367532 0.00004119 0.00035542 0.01222227\n",
      "  0.43063655 0.00066426 0.33291012 0.03812423]\n",
      " [0.00358408 0.0000765  0.00744362 0.00038923 0.00053576 0.00165561\n",
      "  0.9837932  0.00000383 0.00241594 0.00010219]\n",
      " [0.00001709 0.06997965 0.00401104 0.00223667 0.01352338 0.00210408\n",
      "  0.00032992 0.7814209  0.02146219 0.10491505]\n",
      " [0.00062486 0.00033939 0.00084875 0.9717377  0.00010189 0.02277006\n",
      "  0.00012918 0.00003288 0.00294454 0.00047072]\n",
      " [0.00032646 0.00000136 0.0009397  0.00015044 0.93979067 0.00017239\n",
      "  0.00129964 0.00199537 0.00057499 0.05474901]\n",
      " [0.00051839 0.00004953 0.02034656 0.87971586 0.00003037 0.08343984\n",
      "  0.00428051 0.00000658 0.01158717 0.00002531]\n",
      " [0.00001606 0.00591607 0.00024073 0.02156367 0.6595621  0.06120878\n",
      "  0.00379135 0.0001801  0.04338    0.20414099]\n",
      " [0.00000525 0.00001188 0.00000912 0.00017112 0.00000621 0.00002184\n",
      "  0.00000012 0.99878794 0.00000917 0.00097724]\n",
      " [0.00062973 0.09958858 0.00569997 0.7406038  0.00471228 0.07257713\n",
      "  0.00133484 0.00618237 0.0506894  0.01798192]\n",
      " [0.00020919 0.00000751 0.00000857 0.00018674 0.00779117 0.00015313\n",
      "  0.00000847 0.05022973 0.00032659 0.9410789 ]\n",
      " [0.00002471 0.9908221  0.00062009 0.00303755 0.00040225 0.00043215\n",
      "  0.00114282 0.00039    0.00194834 0.00117999]\n",
      " [0.0250964  0.00004649 0.00819626 0.45827016 0.00000241 0.43827623\n",
      "  0.0008173  0.00004272 0.06819815 0.00105388]\n",
      " [0.00070827 0.00000019 0.9959579  0.00030539 0.00002177 0.00000226\n",
      "  0.00197067 0.00000003 0.00103156 0.00000197]\n",
      " [0.00007335 0.00013032 0.00000477 0.00012776 0.11656445 0.00147779\n",
      "  0.00001976 0.00471103 0.01998061 0.85691017]\n",
      " [0.00022122 0.00198863 0.00640996 0.01358497 0.00131275 0.00380712\n",
      "  0.00120218 0.00043215 0.97022164 0.00081933]\n",
      " [0.00001627 0.00000025 0.00000023 0.00000593 0.00001242 0.00001504\n",
      "  0.00000006 0.99823654 0.00000368 0.00170939]\n",
      " [0.00003069 0.00055333 0.9851222  0.00053212 0.00058679 0.00001419\n",
      "  0.01295106 0.00000758 0.00013669 0.00006546]\n",
      " [0.00030466 0.00002594 0.00188726 0.00001499 0.96518487 0.00012735\n",
      "  0.00747206 0.00070977 0.00321815 0.02105497]\n",
      " [0.00001814 0.0000042  0.00002132 0.9972077  0.00000003 0.0005427\n",
      "  0.00000002 0.00104339 0.00077163 0.00039082]\n",
      " [0.00381738 0.00002828 0.00193256 0.04630676 0.00010286 0.9160398\n",
      "  0.00027993 0.00105422 0.01514935 0.01528877]\n",
      " [0.00000845 0.00001321 0.00001462 0.00009849 0.53252697 0.00061059\n",
      "  0.00020666 0.0029155  0.00150179 0.4621037 ]\n",
      " [0.00001413 0.00004209 0.00151026 0.99489105 0.0000001  0.00227437\n",
      "  0.00000359 0.00005186 0.00119288 0.00001971]\n",
      " [0.00415506 0.00002024 0.00253023 0.20025226 0.00000009 0.7925287\n",
      "  0.00010862 0.00000581 0.00039595 0.00000298]\n",
      " [0.00001336 0.0000619  0.00000124 0.00091949 0.00233048 0.00152619\n",
      "  0.00000481 0.6634218  0.00013247 0.33158818]\n",
      " [0.56652063 0.00000313 0.00002316 0.00725789 0.00121582 0.04679125\n",
      "  0.00020489 0.34881225 0.0003741  0.02879687]\n",
      " [0.00000532 0.00000769 0.00000462 0.00005511 0.6836647  0.00005448\n",
      "  0.00014441 0.01488256 0.00078598 0.3003952 ]\n",
      " [0.09995519 0.00000237 0.10415713 0.00023723 0.0007255  0.10783456\n",
      "  0.68646455 0.00000857 0.00054299 0.0000718 ]\n",
      " [0.00176394 0.00453763 0.11651041 0.4622056  0.0001607  0.02089983\n",
      "  0.0004131  0.00093192 0.39218256 0.00039438]\n",
      " [0.00041862 0.00000822 0.0004878  0.00020834 0.0002022  0.00296805\n",
      "  0.0000646  0.00135091 0.98834187 0.00594936]\n",
      " [0.02046818 0.04408929 0.0220818  0.6029197  0.00044148 0.28063476\n",
      "  0.0044121  0.00353136 0.00923601 0.01218535]\n",
      " [0.05667455 0.00103681 0.01715827 0.21601717 0.00005795 0.69302726\n",
      "  0.00282549 0.00653359 0.00445336 0.00221558]\n",
      " [0.00286261 0.00415582 0.00668348 0.0005619  0.17660914 0.00503195\n",
      "  0.01122913 0.00748204 0.08297455 0.7024094 ]\n",
      " [0.00012733 0.00230837 0.01042191 0.00303054 0.00329128 0.0115761\n",
      "  0.00319707 0.00068585 0.9622821  0.00307937]\n",
      " [0.00027103 0.0005111  0.00066602 0.98883224 0.00000716 0.00718007\n",
      "  0.00070548 0.00009976 0.00141702 0.00031012]\n",
      " [0.00068572 0.90862906 0.03153742 0.00264183 0.00851492 0.00133368\n",
      "  0.00272124 0.00300771 0.04012043 0.00080805]\n",
      " [0.00122158 0.00063249 0.02691269 0.00304466 0.00002004 0.0043281\n",
      "  0.00003885 0.00685847 0.9560406  0.0009025 ]\n",
      " [0.00002446 0.9948206  0.00254922 0.00009876 0.00005937 0.0000681\n",
      "  0.00118206 0.00030004 0.00079983 0.00009765]\n",
      " [0.00005147 0.00001447 0.00058633 0.00024649 0.9761287  0.00030389\n",
      "  0.00145066 0.00116509 0.00356972 0.01648314]\n",
      " [0.00026565 0.976939   0.00333446 0.00150458 0.00038797 0.00072475\n",
      "  0.00919375 0.00089171 0.00575399 0.0010041 ]\n",
      " [0.9903706  0.00000028 0.00161978 0.0008432  0.00000342 0.00250994\n",
      "  0.0041767  0.00001017 0.0004362  0.00002975]\n",
      " [0.00000383 0.9946666  0.00011342 0.00055405 0.00012314 0.00054707\n",
      "  0.00043056 0.0001315  0.00314243 0.00028753]\n",
      " [0.00005849 0.0001735  0.00000836 0.00103091 0.02840751 0.00114494\n",
      "  0.0000014  0.02019999 0.00101171 0.94796324]\n",
      " [0.00009265 0.00047521 0.00097342 0.06973252 0.02185126 0.01121889\n",
      "  0.00005845 0.07838184 0.04193716 0.7752786 ]\n",
      " [0.9734875  0.00000001 0.00014049 0.00045872 0.00000031 0.02538429\n",
      "  0.00002    0.0000189  0.00048549 0.00000421]\n",
      " [0.00000901 0.00000139 0.00000022 0.00004928 0.00005539 0.00004866\n",
      "  0.00000002 0.9845258  0.00010213 0.01520807]\n",
      " [0.00003148 0.00010789 0.00004651 0.9951682  0.00000374 0.00331871\n",
      "  0.00000973 0.00020268 0.00069676 0.00041442]\n",
      " [0.00320949 0.03386248 0.01241001 0.0411275  0.00107048 0.00900967\n",
      "  0.00006743 0.78069496 0.01448751 0.10406048]\n",
      " [0.00008578 0.00015905 0.6491144  0.08785876 0.0000149  0.00061505\n",
      "  0.00001726 0.24615864 0.01404109 0.00193508]\n",
      " [0.00063473 0.24233858 0.08482192 0.05496633 0.26722604 0.00574675\n",
      "  0.27624324 0.00187537 0.04663205 0.01951499]\n",
      " [0.00042505 0.00000793 0.00015172 0.00034264 0.8792612  0.00372844\n",
      "  0.00159754 0.00467516 0.00376504 0.10604538]\n",
      " [0.00063565 0.0000156  0.00009394 0.000341   0.09524014 0.00066669\n",
      "  0.00014614 0.0510683  0.00117526 0.85061735]]\n",
      "I0821 04:35:37.252931 140686840100672 basic_session_run_hooks.py:262] loss = 0.32623333, step = 5007\n",
      "I0821 04:35:37.255463 140686840100672 basic_session_run_hooks.py:606] Saving checkpoints for 5008 into /tmp/mnist_convnet_model/model.ckpt.\n",
      "W0821 04:35:37.278174 140686840100672 deprecation.py:323] From /home/dreuter/.julia/conda/3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "I0821 04:35:37.389363 140686840100672 estimator.py:368] Loss for final step: 0.32623333.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7ff3872a2d50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train one step and display the probabilties\n",
    "mnist_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=1,\n",
    "    hooks=[logging_hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0821 04:35:37.439172 140686840100672 estimator.py:1145] Calling model_fn.\n",
      "I0821 04:35:37.676684 140686840100672 estimator.py:1147] Done calling model_fn.\n",
      "I0821 04:35:37.678834 140686840100672 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0821 04:35:37.839030 140686840100672 monitored_session.py:240] Graph was finalized.\n",
      "I0821 04:35:37.843471 140686840100672 saver.py:1280] Restoring parameters from /tmp/mnist_convnet_model/model.ckpt-5008\n",
      "I0821 04:35:37.954499 140686840100672 session_manager.py:500] Running local_init_op.\n",
      "I0821 04:35:37.972320 140686840100672 session_manager.py:502] Done running local_init_op.\n",
      "I0821 04:35:38.562334 140686840100672 basic_session_run_hooks.py:606] Saving checkpoints for 5008 into /tmp/mnist_convnet_model/model.ckpt.\n",
      "I0821 04:35:38.877775 140686840100672 basic_session_run_hooks.py:262] loss = 0.23692617, step = 5008\n",
      "I0821 04:35:39.654380 140686840100672 basic_session_run_hooks.py:692] global_step/sec: 128.703\n",
      "I0821 04:35:39.656313 140686840100672 basic_session_run_hooks.py:260] loss = 0.35925543, step = 5108 (0.779 sec)\n",
      "I0821 04:35:40.665212 140686840100672 basic_session_run_hooks.py:692] global_step/sec: 99.0251\n",
      "I0821 04:35:40.672277 140686840100672 basic_session_run_hooks.py:260] loss = 0.25903776, step = 5208 (1.016 sec)\n",
      "I0821 04:35:41.478670 140686840100672 basic_session_run_hooks.py:692] global_step/sec: 122.782\n",
      "I0821 04:35:41.479952 140686840100672 basic_session_run_hooks.py:260] loss = 0.23717862, step = 5308 (0.808 sec)\n",
      "I0821 04:35:42.210732 140686840100672 basic_session_run_hooks.py:692] global_step/sec: 136.594\n",
      "I0821 04:35:42.212113 140686840100672 basic_session_run_hooks.py:260] loss = 0.30068207, step = 5408 (0.732 sec)\n",
      "I0821 04:35:42.902045 140686840100672 basic_session_run_hooks.py:692] global_step/sec: 144.654\n",
      "I0821 04:35:42.903192 140686840100672 basic_session_run_hooks.py:260] loss = 0.21884753, step = 5508 (0.691 sec)\n",
      "I0821 04:35:43.607862 140686840100672 basic_session_run_hooks.py:692] global_step/sec: 141.703\n",
      "I0821 04:35:43.609985 140686840100672 basic_session_run_hooks.py:260] loss = 0.3260987, step = 5608 (0.707 sec)\n",
      "I0821 04:35:44.310329 140686840100672 basic_session_run_hooks.py:692] global_step/sec: 142.345\n",
      "I0821 04:35:44.313451 140686840100672 basic_session_run_hooks.py:260] loss = 0.23284604, step = 5708 (0.703 sec)\n",
      "I0821 04:35:45.011163 140686840100672 basic_session_run_hooks.py:692] global_step/sec: 142.673\n",
      "I0821 04:35:45.012716 140686840100672 basic_session_run_hooks.py:260] loss = 0.33858773, step = 5808 (0.699 sec)\n",
      "I0821 04:35:45.739123 140686840100672 basic_session_run_hooks.py:692] global_step/sec: 137.373\n",
      "I0821 04:35:45.740316 140686840100672 basic_session_run_hooks.py:260] loss = 0.23228313, step = 5908 (0.728 sec)\n",
      "I0821 04:35:46.415318 140686840100672 basic_session_run_hooks.py:606] Saving checkpoints for 6008 into /tmp/mnist_convnet_model/model.ckpt.\n",
      "I0821 04:35:46.508422 140686840100672 estimator.py:368] Loss for final step: 0.3154648.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7ff3872a2d50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_classifier.train(input_fn=train_input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0821 04:35:46.549117 140686840100672 estimator.py:1145] Calling model_fn.\n",
      "I0821 04:35:46.705175 140686840100672 estimator.py:1147] Done calling model_fn.\n",
      "I0821 04:35:46.725710 140686840100672 evaluation.py:255] Starting evaluation at 2019-08-21T04:35:46Z\n",
      "I0821 04:35:46.837448 140686840100672 monitored_session.py:240] Graph was finalized.\n",
      "I0821 04:35:46.841138 140686840100672 saver.py:1280] Restoring parameters from /tmp/mnist_convnet_model/model.ckpt-6008\n",
      "I0821 04:35:46.914422 140686840100672 session_manager.py:500] Running local_init_op.\n",
      "I0821 04:35:46.930656 140686840100672 session_manager.py:502] Done running local_init_op.\n",
      "I0821 04:35:47.600253 140686840100672 evaluation.py:275] Finished evaluation at 2019-08-21-04:35:47\n",
      "I0821 04:35:47.602672 140686840100672 estimator.py:2039] Saving dict for global step 6008: accuracy = 0.9332, global_step = 6008, loss = 0.23350136\n",
      "I0821 04:35:47.675389 140686840100672 estimator.py:2099] Saving 'checkpoint_path' summary for global step 6008: /tmp/mnist_convnet_model/model.ckpt-6008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9332, 'loss': 0.23350136, 'global_step': 6008}\n"
     ]
    }
   ],
   "source": [
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data},\n",
    "    y=eval_labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 Conda",
   "language": "python",
   "name": "python3conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
